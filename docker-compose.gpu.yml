# ============================================
# DEPRECATED - Use profiles instead:
#   docker-compose --profile gpu up -d
#
# This file is kept for reference only.
# All GPU configuration is now in docker-compose.yml
# ============================================

# GPU Override for Rice Search Platform (DEPRECATED)
# Usage: docker compose -f docker-compose.yml -f docker-compose.gpu.yml up -d
#
# Requirements:
#   - NVIDIA GPU with CUDA support
#   - nvidia-container-toolkit installed
#   - Docker configured with nvidia runtime
#
# GPU Memory Requirements (approximate):
#   - Infinity (embeddings + reranking): ~4-8GB VRAM
#   - Milvus: ~2-4GB VRAM depending on index size
#   - Total recommended: 8GB+ VRAM

services:
  # ============================================
  # Milvus with GPU acceleration
  # Accelerates vector similarity search
  # ============================================
  milvus:
    image: milvusdb/milvus:v2.4.15-gpu
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
      MINIO_USE_SSL: "false"
      MINIO_REGION: us-east-1
      
      # ========== GPU Configuration ==========
      CUDA_VISIBLE_DEVICES: "0"
      KNOWHERE_GPU_MEM_POOL_SIZE: "2048:4096"   # GPU memory pool (init:max MB)
      GPU_SEARCH_THRESHOLD: "100"               # Use GPU for >100 vectors
      
      # ========== PROXY (Connection Layer) ==========
      PROXY_MAX_CONNECTIONS: "65535"
      PROXY_MAX_TASK_NUM: "4096"                # Higher for GPU
      PROXY_MAXMSGSIZE: "536870912"             # 512MB for GPU batches
      PROXY_GINLOGGING: "false"
      
      # ========== QUERY NODE (GPU Search) ==========
      QUERYNODE_SCHEDULER_MAXREADCONCURRENCY: "512"     # Higher for GPU
      QUERYNODE_SCHEDULER_SCHEDULETIMEOUT: "10000"
      QUERYNODE_GROUPING_ENABLED: "true"
      QUERYNODE_GROUPING_MAXNQ: "2000"                  # Larger batches for GPU
      QUERYNODE_SEGCORE_CHUNKROWS: "2048"               # Larger chunks for GPU
      QUERYNODE_CACHE_ENABLED: "true"
      QUERYNODE_CACHE_SIZE: "4294967296"                # 4GB cache with GPU
      QUERYNODE_LOADMEMORYLIMIT: "10737418240"          # 10GB for GPU mode
      
      # ========== DATA NODE (Indexing) ==========
      DATANODE_FLUSH_INSERT_BUFFER_SIZE: "536870912"    # 512MB for GPU
      DATANODE_FLOWGRAPH_MAXQUEUELEN: "32"
      DATANODE_FLOWGRAPH_MAXPARALLELISM: "16"           # Higher for GPU
      DATANODE_SEGMENT_INSERTBUFFERSIZE: "33554432"     # 32MB per segment
      
      # ========== INDEX NODE (GPU Index Building) ==========
      INDEXNODE_SCHEDULER_BUILDPARALLEL: "8"            # More parallel on GPU
      INDEXNODE_ENABLEDISK: "true"
      
      # ========== COORD ==========
      QUERYCOORD_TASK_MERGEIDX: "32"
      QUERYCOORD_SCHEDULERTASKQUEUECAP: "20000"
      DATACOORD_SEGMENT_MAXSIZE: "2048"                 # 2GB segments for GPU
      DATACOORD_SEGMENT_SEALEDMAXSIZE: "4096"           # 4GB sealed
      DATACOORD_COMPACTION_ENABLED: "true"
      
      # ========== gRPC PERFORMANCE ==========
      GRPC_SERVERMAXTOKENPERSET: "2147483648"           # 2GB for GPU
      COMMON_MAXMSGSIZE: "536870912"                    # 512MB
      GRPC_CLIENTMAXSENDSIZE: "536870912"
      GRPC_CLIENTMAXRECVSIZE: "536870912"
      GRPC_SERVERMAXSENDSIZE: "536870912"
      GRPC_SERVERMAXRECVSIZE: "536870912"
      
      # ========== MEMORY & QUOTAS ==========
      COMMON_STORAGETYPE: "local"
      QUOTAANDLIMITS_ENABLED: "true"
      QUOTAANDLIMITS_DDLENABLED: "false"
      QUOTAANDLIMITS_INDEXRATEENABLED: "false"
      QUOTAANDLIMITS_FLUSHRATEENABLED: "false"
      
      # ========== GENERAL ==========
      COMMON_GRACEFUL_TIME: "5000"
      COMMON_GRACEFUL_STOP_TIMEOUT: "30"
      LOG_LEVEL: "warn"
    deploy:
      resources:
        limits:
          memory: 12G
        reservations:
          memory: 4G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # ============================================
  # Infinity with GPU acceleration
  # ~10x faster embedding/reranking with GPU
  #
  # Default Models (Dec 2025 - optimized for code search):
  # - jinaai/jina-code-embeddings-1.5b (1536d, Rust/Kotlin/15+ languages)
  # - jinaai/jina-reranker-v2-base-multilingual (code-optimized, 15-30ms GPU)
  #
  # Configure via .env or environment variables
  # ============================================
  infinity:
    image: michaelf34/infinity:latest
    command: >
      v2
      --model-id ${EMBED_MODEL:-jinaai/jina-code-embeddings-1.5b}
      --model-id ${RERANK_MODEL:-jinaai/jina-reranker-v2-base-multilingual}
      --engine ${INFINITY_ENGINE:-torch}
      --port 80
      --batch-size ${INFINITY_BATCH_SIZE:-64}
      --device cuda
    environment:
      - HF_HOME=/app/.cache
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN:-}
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
