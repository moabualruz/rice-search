# GPU Override for Rice Search Platform
# Usage: docker compose -f docker-compose.yml -f docker-compose.gpu.yml up -d
#
# Requirements:
#   - NVIDIA GPU with CUDA support
#   - nvidia-container-toolkit installed
#   - Docker configured with nvidia runtime
#
# GPU Memory Requirements (approximate):
#   - Infinity (embeddings + reranking): ~4-6GB VRAM
#   - BGE-M3 (if using): ~4-6GB VRAM
#   - Milvus: ~2-4GB VRAM depending on index size
#   - Total recommended: 8GB+ VRAM

services:
  # ============================================
  # Milvus with GPU acceleration
  # Accelerates vector similarity search
  # ============================================
  milvus:
    image: milvusdb/milvus:v2.4.13-gpu
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
      MINIO_USE_SSL: "false"
      MINIO_REGION: us-east-1
      # GPU Configuration
      CUDA_VISIBLE_DEVICES: "0"
      # Enable GPU for indexing and search
      KNOWHERE_GPU_MEM_POOL_SIZE: "2048:4096"
      # Performance tuning (inherited + GPU specific)
      QUERY_NODE_MAX_CONCURRENT: "512"
      PROXY_MAX_TASK_NUM: "2048"
      QUERYNODE_CACHE_ENABLED: "true"
      QUERYNODE_CACHE_SIZE: "2147483648"  # 2GB cache with GPU
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # ============================================
  # Infinity with GPU acceleration
  # Serves both mxbai-embed-large-v1 and mxbai-rerank-base-v2
  # ~10x faster embedding generation with GPU
  # ============================================
  infinity:
    image: michaelf34/infinity:latest
    command: >
      v2
      --model-id mixedbread-ai/mxbai-embed-large-v1
      --model-id mixedbread-ai/mxbai-rerank-base-v2
      --port 80
      --batch-size 64
      --device cuda
    environment:
      - HF_HOME=/app/.cache
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN:-}
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # ============================================
  # BGE-M3 with GPU acceleration (Phase 2)
  # Dense + Sparse + ColBERT in one model
  # ============================================
  bge-m3:
    environment:
      - DEVICE=cuda
      - USE_FP16=true
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
