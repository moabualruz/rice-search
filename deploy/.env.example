# Rice Search - Xinference Configuration
# Models are loaded dynamically via Xinference API

# =============================================================================
# XINFERENCE URL
# =============================================================================
XINFERENCE_URL=http://xinference:9997

# =============================================================================
# MODEL NAMES (for Xinference to load)
# =============================================================================

# Dense Embeddings - loaded as "embedding" type in Xinference
# Supported: bge-base-en-v1.5, jina-embeddings-v3, e5-large-v2, bge-m3
EMBEDDING_MODEL=jina-embeddings-v3

# Sparse Model (keyword-based fallback - no native SPLADE in Xinference)
SPARSE_MODEL=bm25

# Reranking Model - loaded as "rerank" type in Xinference
# Supported: bge-reranker-base, jina-reranker-v2-base-multilingual
RERANK_MODEL=BAAI/bge-reranker-base

# LLM for RAG Chat & Query Classification - loaded as "LLM" type
LLM_MODEL=codellama

# =============================================================================
# EMBEDDING DIMENSION
# =============================================================================
# Must match the model's output dimension:
# - jina-embeddings-v3: 1024
# - bge-base-en-v1.5: 768
# - e5-large-v2: 1024
EMBEDDING_DIM=1024

# =============================================================================
# RERANKING MODE
# =============================================================================
# "rerank" = Use Xinference rerank endpoint (requires rerank model loaded)
# "llm" = Use LLM prompting for reranking (no extra model needed)
RERANK_MODE=llm
