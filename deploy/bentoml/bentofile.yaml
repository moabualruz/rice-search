service: "service:RiceInferenceService"
name: rice-inference
labels:
  project: rice-search
  component: inference

include:
  - "*.py"

python:
  packages:
    - torch>=2.0.0
    - sentence-transformers>=2.2.0
    - vllm>=0.4.0
    - transformers>=4.40.0
    - accelerate>=0.20.0
    - pydantic>=2.0.0
    - einops
    - flash-attn

docker:
  cuda_version: "12.1"
  python_version: "3.10"
  system_packages:
    - git
    - curl
  env:
    - HF_HOME=/root/.cache/huggingface
    - EMBEDDING_MODEL=jinaai/jina-embeddings-v3
    - RERANK_MODEL=BAAI/bge-reranker-base
    - LLM_MODEL=Qwen/Qwen2.5-Coder-1.5B-Instruct-AWQ
