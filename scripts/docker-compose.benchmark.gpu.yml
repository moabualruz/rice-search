# Rice Search Benchmark - GPU Override
# Use with: docker compose -f scripts/docker-compose.benchmark.yml -f scripts/docker-compose.benchmark.gpu.yml up -d
#
# Same GPU configuration as main docker-compose.gpu.yml

services:
  # ============================================
  # Milvus with GPU acceleration
  # Same as main docker-compose.gpu.yml
  # ============================================
  milvus:
    image: milvusdb/milvus:v2.4.15-gpu
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
      MINIO_USE_SSL: "false"
      MINIO_REGION: us-east-1
      # GPU Configuration
      CUDA_VISIBLE_DEVICES: "0"
      # Enable GPU for indexing and search
      KNOWHERE_GPU_MEM_POOL_SIZE: "2048:4096"
      # Performance tuning (inherited + GPU specific)
      QUERY_NODE_MAX_CONCURRENT: "512"
      PROXY_MAX_TASK_NUM: "2048"
      QUERYNODE_CACHE_ENABLED: "true"
      QUERYNODE_CACHE_SIZE: "2147483648"  # 2GB cache with GPU
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # ============================================
  # Infinity: GPU-accelerated embedding + reranking
  # Same as main docker-compose.gpu.yml
  # ============================================
  infinity:
    container_name: bench-infinity-gpu
    image: michaelf34/infinity:latest
    command: >
      v2
      --model-id mixedbread-ai/mxbai-embed-large-v1
      --model-id mixedbread-ai/mxbai-rerank-xsmall-v1
      --engine torch
      --port 80
      --batch-size 64
      --device cuda
    ports:
      - "8081:80"
    environment:
      - HF_HOME=/app/.cache
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN:-}
      - CUDA_VISIBLE_DEVICES=0
      - INFINITY_ENGINE=torch
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # ============================================
  # BGE-M3: GPU-accelerated embeddings
  # Same as main docker-compose.gpu.yml
  # ============================================
  bge-m3:
    container_name: bench-bge-m3-gpu
    environment:
      - DEVICE=cuda
      - USE_FP16=true
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
